{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Hand Crafted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:07:06.216608Z",
     "iopub.status.busy": "2025-03-25T07:07:06.216471Z",
     "iopub.status.idle": "2025-03-25T07:07:07.675115Z",
     "shell.execute_reply": "2025-03-25T07:07:07.674787Z",
     "shell.execute_reply.started": "2025-03-25T07:07:06.216597Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:07:07.675829Z",
     "iopub.status.busy": "2025-03-25T07:07:07.675658Z",
     "iopub.status.idle": "2025-03-25T07:07:07.678808Z",
     "shell.execute_reply": "2025-03-25T07:07:07.678411Z",
     "shell.execute_reply.started": "2025-03-25T07:07:07.675818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths to dataset\n",
    "dataset_path = \"classification_dataset\"  # Using raw strings bacause the file names contain backslashes and escape characters\n",
    "mask_path = os.path.join(dataset_path, \"with_mask\")\n",
    "no_mask_path = os.path.join(dataset_path, \"without_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:07:07.679246Z",
     "iopub.status.busy": "2025-03-25T07:07:07.679118Z",
     "iopub.status.idle": "2025-03-25T07:07:07.686404Z",
     "shell.execute_reply": "2025-03-25T07:07:07.685816Z",
     "shell.execute_reply.started": "2025-03-25T07:07:07.679233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image not loaded correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.310] global loadsave.cpp:268 findDecoder imread_('classification_dataset\\with_mask\\0_0_≈˙◊¢ 2020-02-23 132115.png'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "#loading a sample image to show that images with 0_0_≈˙◊¢ are not loading correctly\n",
    "sample_image = cv2.imread(r'classification_dataset\\with_mask\\0_0_≈˙◊¢ 2020-02-23 132115.png')\n",
    "if sample_image is None:\n",
    "    print('Image not loaded correctly')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the images with this kind of a name are not being loaded.Manual inspection shows that these kind of images only exist in the with_mask category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:07:07.686894Z",
     "iopub.status.busy": "2025-03-25T07:07:07.686770Z",
     "iopub.status.idle": "2025-03-25T07:07:07.693513Z",
     "shell.execute_reply": "2025-03-25T07:07:07.693139Z",
     "shell.execute_reply.started": "2025-03-25T07:07:07.686885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming completed!\n"
     ]
    }
   ],
   "source": [
    "# Now we create a python script to rename all the wrongly names images\n",
    "import os\n",
    "\n",
    "# Define the folder path where images are stored\n",
    "folder_path = mask_path\n",
    "\n",
    "# Define the characters to be replaced\n",
    "special_chars = \"≈˙◊¢\"\n",
    "\n",
    "# List all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    old_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    # Replace specific special characters with '_'\n",
    "    new_filename = filename\n",
    "    for char in special_chars:\n",
    "        new_filename = new_filename.replace(char, \"_\")\n",
    "\n",
    "    new_path = os.path.join(folder_path, new_filename)\n",
    "\n",
    "    # Rename the file if necessary\n",
    "    if old_path != new_path:\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed: {filename} → {new_filename}\")\n",
    "\n",
    "print(\"Renaming completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there will be no problem in loading any of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:07:07.694488Z",
     "iopub.status.busy": "2025-03-25T07:07:07.694230Z",
     "iopub.status.idle": "2025-03-25T07:07:07.698226Z",
     "shell.execute_reply": "2025-03-25T07:07:07.697794Z",
     "shell.execute_reply.started": "2025-03-25T07:07:07.694476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "def extract_hog_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features, _ = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), \n",
    "                      block_norm='L2-Hys', visualize=True)\n",
    "    return features\n",
    "\n",
    "def extract_lbp_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 10))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:07:07.698609Z",
     "iopub.status.busy": "2025-03-25T07:07:07.698514Z",
     "iopub.status.idle": "2025-03-25T07:07:07.712052Z",
     "shell.execute_reply": "2025-03-25T07:07:07.711403Z",
     "shell.execute_reply.started": "2025-03-25T07:07:07.698600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images with Mask: 2165\n",
      "Images without Mask: 1930\n"
     ]
    }
   ],
   "source": [
    "# Iterate directory\n",
    "def count_images(dir_path):\n",
    "    count = 0\n",
    "    for path in os.listdir(dir_path):\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            count += 1\n",
    "    return count\n",
    "print('Images with Mask:',count_images(mask_path))\n",
    "print('Images without Mask:',count_images(no_mask_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:07:07.712898Z",
     "iopub.status.busy": "2025-03-25T07:07:07.712726Z",
     "iopub.status.idle": "2025-03-25T07:08:12.977782Z",
     "shell.execute_reply": "2025-03-25T07:08:12.977144Z",
     "shell.execute_reply.started": "2025-03-25T07:07:07.712886Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and extract features\n",
    "X, y = [], []\n",
    "\n",
    "for label, path in enumerate([mask_path, no_mask_path]):  # 0: with_mask, 1: without_mask\n",
    "    for file in os.listdir(path):\n",
    "        img_path = os.path.join(path, file)  # Use raw string path\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            # Extract features\n",
    "            hog_feat = extract_hog_features(image)\n",
    "            lbp_feat = extract_lbp_features(image)\n",
    "            color_feat = extract_color_histogram(image)\n",
    "            # Combine features\n",
    "            combined_features = np.hstack([hog_feat, lbp_feat, color_feat])\n",
    "            X.append(combined_features)\n",
    "            y.append(label)\n",
    "        else:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:08:12.978409Z",
     "iopub.status.busy": "2025-03-25T07:08:12.978248Z",
     "iopub.status.idle": "2025-03-25T07:08:13.707548Z",
     "shell.execute_reply": "2025-03-25T07:08:13.706756Z",
     "shell.execute_reply.started": "2025-03-25T07:08:12.978396Z"
    }
   },
   "outputs": [],
   "source": [
    "# **Simplified Train-Validation-Test Split (70%-15%-15%)**\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:08:13.708299Z",
     "iopub.status.busy": "2025-03-25T07:08:13.708181Z",
     "iopub.status.idle": "2025-03-25T07:08:25.118711Z",
     "shell.execute_reply": "2025-03-25T07:08:25.118364Z",
     "shell.execute_reply.started": "2025-03-25T07:08:13.708287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       332\n",
      "           1       0.88      0.89      0.88       282\n",
      "\n",
      "    accuracy                           0.89       614\n",
      "   macro avg       0.89      0.89      0.89       614\n",
      "weighted avg       0.89      0.89      0.89       614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVC\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_val_preds = svm.predict(X_val)\n",
    "svm_f1 = f1_score(y_val, svm_val_preds)\n",
    "print(classification_report(y_val, svm_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:08:25.119079Z",
     "iopub.status.busy": "2025-03-25T07:08:25.118982Z",
     "iopub.status.idle": "2025-03-25T07:08:30.580920Z",
     "shell.execute_reply": "2025-03-25T07:08:30.580631Z",
     "shell.execute_reply.started": "2025-03-25T07:08:25.119071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       332\n",
      "           1       0.92      0.93      0.92       282\n",
      "\n",
      "    accuracy                           0.93       614\n",
      "   macro avg       0.93      0.93      0.93       614\n",
      "weighted avg       0.93      0.93      0.93       614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Neural Network Classifier\n",
    "nn = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "nn.fit(X_train, y_train)\n",
    "nn_val_preds = nn.predict(X_val)\n",
    "nn_f1 = f1_score(y_val, nn_val_preds)\n",
    "print(classification_report(y_val, nn_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:08:30.584715Z",
     "iopub.status.busy": "2025-03-25T07:08:30.584021Z",
     "iopub.status.idle": "2025-03-25T07:09:10.350329Z",
     "shell.execute_reply": "2025-03-25T07:09:10.349842Z",
     "shell.execute_reply.started": "2025-03-25T07:08:30.584700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       332\n",
      "           1       0.95      0.88      0.91       282\n",
      "\n",
      "    accuracy                           0.92       614\n",
      "   macro avg       0.93      0.92      0.92       614\n",
      "weighted avg       0.92      0.92      0.92       614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost Classifier\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42,n_jobs=-1)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_val_preds = xgb.predict(X_val)\n",
    "xgb_f1 = f1_score(y_val, xgb_val_preds)\n",
    "print(classification_report(y_val, xgb_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:10.350744Z",
     "iopub.status.busy": "2025-03-25T07:09:10.350639Z",
     "iopub.status.idle": "2025-03-25T07:09:10.381174Z",
     "shell.execute_reply": "2025-03-25T07:09:10.380703Z",
     "shell.execute_reply.started": "2025-03-25T07:09:10.350733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Scores: SVM=0.8834, NN=0.9206, XGBoost=0.9138\n",
      "Best Model: Neural Network with Validation F1-Score = 0.9206\n",
      "Test F1-Score for Best Model (Neural Network): 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       340\n",
      "           1       0.93      0.95      0.94       275\n",
      "\n",
      "    accuracy                           0.94       615\n",
      "   macro avg       0.94      0.94      0.94       615\n",
      "weighted avg       0.94      0.94      0.94       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# **Choose Best Model Based on F1-Score**\n",
    "best_model_name, best_model, best_f1_score = max(\n",
    "    zip([\"SVM\", \"Neural Network\", \"XGBoost\"], \n",
    "        [svm, nn, xgb], \n",
    "        [svm_f1, nn_f1, xgb_f1]), \n",
    "    key=lambda x: x[2]\n",
    ")\n",
    "\n",
    "# **Final Testing on the Best Model**\n",
    "final_test_preds = best_model.predict(X_test)\n",
    "final_test_f1 = f1_score(y_test, final_test_preds)\n",
    "final_test_report = classification_report(y_test, final_test_preds)\n",
    "\n",
    "# **Print Results**\n",
    "print(f\"Validation F1-Scores: SVM={svm_f1:.4f}, NN={nn_f1:.4f}, XGBoost={xgb_f1:.4f}\")\n",
    "print(f\"Best Model: {best_model_name} with Validation F1-Score = {best_f1_score:.4f}\")\n",
    "print(f\"Test F1-Score for Best Model ({best_model_name}): {final_test_f1:.4f}\")\n",
    "print(final_test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN(Automatic Feature Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:10.381862Z",
     "iopub.status.busy": "2025-03-25T07:09:10.381675Z",
     "iopub.status.idle": "2025-03-25T07:09:13.112205Z",
     "shell.execute_reply": "2025-03-25T07:09:13.111635Z",
     "shell.execute_reply.started": "2025-03-25T07:09:10.381847Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:39:10.932968: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-25 12:39:11.200481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742886551.297116    2951 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742886551.322134    2951 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 12:39:11.549080: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Rescaling, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:13.113304Z",
     "iopub.status.busy": "2025-03-25T07:09:13.113106Z",
     "iopub.status.idle": "2025-03-25T07:09:13.115038Z",
     "shell.execute_reply": "2025-03-25T07:09:13.114805Z",
     "shell.execute_reply.started": "2025-03-25T07:09:13.113293Z"
    }
   },
   "outputs": [],
   "source": [
    "# def rename(dataset_path,string):\n",
    "#     # Get all image files\n",
    "#     image_files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n",
    "\n",
    "#     # Rename files sequentially\n",
    "#     for index, filename in enumerate(image_files, start=1):\n",
    "#         old_path = os.path.join(dataset_path, filename)\n",
    "\n",
    "#         # Extract the file extension (e.g., .jpg, .png)\n",
    "#         extension = os.path.splitext(filename)[1]  # Includes the dot\n",
    "\n",
    "#         # Generate new filename\n",
    "#         new_filename = f\"image_{string}_{index}{extension}\"\n",
    "#         new_path = os.path.join(dataset_path, new_filename)\n",
    "\n",
    "#         # Rename the file\n",
    "#         os.rename(old_path, new_path)\n",
    "#         # print(f\"Renamed: {filename} → {new_filename}\")\n",
    "\n",
    "# print(\" All images renamed\")\n",
    "\n",
    "# rename(r\"classification_dataset/with_mask\", 'with_mask')\n",
    "# rename(r\"classification_dataset/without_mask\", 'without_mask')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:13.115465Z",
     "iopub.status.busy": "2025-03-25T07:09:13.115298Z",
     "iopub.status.idle": "2025-03-25T07:09:14.295882Z",
     "shell.execute_reply": "2025-03-25T07:09:14.295376Z",
     "shell.execute_reply.started": "2025-03-25T07:09:13.115455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4092 files belonging to 2 classes.\n",
      "Using 2865 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742886553.459515    2951 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6196 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dataset_path = \"classification_dataset\"  # Using raw strings bacause the file names contain backslashes and escape characters\n",
    "\n",
    "batch_size = 32\n",
    "img_size = (128, 128)\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.3,  \n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:14.296405Z",
     "iopub.status.busy": "2025-03-25T07:09:14.296268Z",
     "iopub.status.idle": "2025-03-25T07:09:14.362608Z",
     "shell.execute_reply": "2025-03-25T07:09:14.362353Z",
     "shell.execute_reply.started": "2025-03-25T07:09:14.296393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4092 files belonging to 2 classes.\n",
      "Using 1227 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_test_ds = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.3,  \n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:14.363006Z",
     "iopub.status.busy": "2025-03-25T07:09:14.362893Z",
     "iopub.status.idle": "2025-03-25T07:09:14.370125Z",
     "shell.execute_reply": "2025-03-25T07:09:14.369752Z",
     "shell.execute_reply.started": "2025-03-25T07:09:14.362997Z"
    }
   },
   "outputs": [],
   "source": [
    "# **Further split val_test into validation (15%) and test (15%)**\n",
    "val_size = int(0.5 * len(val_test_ds))  # 50% of remaining 30% goes to validation\n",
    "val_ds = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:14.370720Z",
     "iopub.status.busy": "2025-03-25T07:09:14.370556Z",
     "iopub.status.idle": "2025-03-25T07:09:14.372577Z",
     "shell.execute_reply": "2025-03-25T07:09:14.372245Z",
     "shell.execute_reply.started": "2025-03-25T07:09:14.370709Z"
    }
   },
   "outputs": [],
   "source": [
    "# # **Data Augmentation (Mapped to Training Set)**\n",
    "# def augment(image, label):\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "#     image = tf.image.random_rotation(image, 0.1)\n",
    "#     return image, label\n",
    "\n",
    "# train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:14.373274Z",
     "iopub.status.busy": "2025-03-25T07:09:14.373080Z",
     "iopub.status.idle": "2025-03-25T07:09:14.388619Z",
     "shell.execute_reply": "2025-03-25T07:09:14.387723Z",
     "shell.execute_reply.started": "2025-03-25T07:09:14.373257Z"
    }
   },
   "outputs": [],
   "source": [
    "# **Enable Caching & Prefetching for Faster Performance**\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:14.389396Z",
     "iopub.status.busy": "2025-03-25T07:09:14.389272Z",
     "iopub.status.idle": "2025-03-25T07:09:14.401171Z",
     "shell.execute_reply": "2025-03-25T07:09:14.400579Z",
     "shell.execute_reply.started": "2025-03-25T07:09:14.389384Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Rescaling\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_cnn(activation='relu', optimizer=Adam(learning_rate=0.001), dropout_rate=0.5):\n",
    "    model = Sequential([\n",
    "        Input(shape=(128, 128, 3)),  # Explicit Input Layer\n",
    "        Rescaling(1./255),  # Rescale pixel values\n",
    "        \n",
    "        Conv2D(32, (3,3), activation=activation, padding='valid'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "\n",
    "        Conv2D(64, (3,3), activation=activation, padding='valid'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation=activation),\n",
    "        Dropout(dropout_rate),  # Dropout to prevent overfitting\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:14.401803Z",
     "iopub.status.busy": "2025-03-25T07:09:14.401605Z",
     "iopub.status.idle": "2025-03-25T07:09:38.934747Z",
     "shell.execute_reply": "2025-03-25T07:09:38.934249Z",
     "shell.execute_reply.started": "2025-03-25T07:09:14.401785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:39:15.675244: W tensorflow/core/lib/png/png_io.cc:89] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2025-03-25 12:39:15.938297: W tensorflow/core/lib/png/png_io.cc:89] PNG warning: iCCP: known incorrect sRGB profile\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742886556.163950    4345 service.cc:148] XLA service 0x7d722000db70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742886556.166923    4345 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-03-25 12:39:16.207305: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742886556.371324    4345 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/90\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7280 - loss: 1.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742886558.299110    4345 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.8424 - loss: 0.6568 - val_accuracy: 0.4655 - val_loss: 1.4383\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9568 - loss: 0.1135 - val_accuracy: 0.4704 - val_loss: 3.0626\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9863 - loss: 0.0509 - val_accuracy: 0.5247 - val_loss: 3.2846\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9806 - loss: 0.0482 - val_accuracy: 0.7780 - val_loss: 1.1368\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0258 - val_accuracy: 0.8355 - val_loss: 0.8419\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9922 - loss: 0.0226 - val_accuracy: 0.9178 - val_loss: 0.3918\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9880 - loss: 0.0321 - val_accuracy: 0.9309 - val_loss: 0.4594\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9912 - loss: 0.0293 - val_accuracy: 0.9507 - val_loss: 0.3471\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9906 - loss: 0.0274 - val_accuracy: 0.9638 - val_loss: 0.2484\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9948 - loss: 0.0210 - val_accuracy: 0.9720 - val_loss: 0.2073\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9941 - loss: 0.0139 - val_accuracy: 0.9589 - val_loss: 0.2864\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.9589 - val_loss: 0.2519\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9638 - val_loss: 0.2145\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9638 - val_loss: 0.2303\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9605 - val_loss: 0.2592\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=5,         # Stop after 10 epochs with no improvement\n",
    "    restore_best_weights=True,  # Restore best weights\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create model\n",
    "model = create_cnn(activation='relu', optimizer=Adam(0.0001), dropout_rate=0.5)\n",
    "\n",
    "# Train model with early stopping\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]  # Add early stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:09:38.935473Z",
     "iopub.status.busy": "2025-03-25T07:09:38.935331Z",
     "iopub.status.idle": "2025-03-25T07:20:24.189504Z",
     "shell.execute_reply": "2025-03-25T07:20:24.189224Z",
     "shell.execute_reply.started": "2025-03-25T07:09:38.935460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=Adam, Activation=relu, Dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:39:57.352343: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=Adam, Activation=relu, Dropout=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:40:22.647526: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=Adam, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=Adam, Activation=elu, Dropout=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:41:04.329789: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=RMSprop, Activation=relu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=RMSprop, Activation=relu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=RMSprop, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=16, Optimizer=RMSprop, Activation=elu, Dropout=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:42:16.862191: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=Adam, Activation=relu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=Adam, Activation=relu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=Adam, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=Adam, Activation=elu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=RMSprop, Activation=relu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=RMSprop, Activation=relu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=RMSprop, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.001, Batch=32, Optimizer=RMSprop, Activation=elu, Dropout=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:45:08.774687: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=Adam, Activation=relu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=Adam, Activation=relu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=Adam, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=Adam, Activation=elu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=RMSprop, Activation=relu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=RMSprop, Activation=relu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=RMSprop, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=16, Optimizer=RMSprop, Activation=elu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=Adam, Activation=relu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=Adam, Activation=relu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=Adam, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=Adam, Activation=elu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=RMSprop, Activation=relu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=RMSprop, Activation=relu, Dropout=0.5\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=RMSprop, Activation=elu, Dropout=0.3\n",
      "\n",
      "Training CNN with: LR=0.0001, Batch=32, Optimizer=RMSprop, Activation=elu, Dropout=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:50:24.185293: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# **Hyperparameter Variations**\n",
    "learning_rates = [0.001, 0.0001]\n",
    "batch_sizes = [16, 32]\n",
    "optimizers = [Adam, RMSprop]\n",
    "activations = ['relu','elu']\n",
    "dropout_rates = [0.3, 0.5]\n",
    "\n",
    "# **Training and Comparing Different CNNs**\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for optimizer in optimizers:\n",
    "            for activation in activations:\n",
    "                for dropout_rate in dropout_rates:\n",
    "                    print(f\"\\nTraining CNN with: LR={lr}, Batch={batch_size}, Optimizer={optimizer.__name__}, Activation={activation}, Dropout={dropout_rate}\")\n",
    "\n",
    "                    # Create and train CNN\n",
    "                    # Define early stopping\n",
    "                    early_stopping = EarlyStopping(\n",
    "                                                    monitor='val_loss',  # Monitor validation loss\n",
    "                                                    patience=5,         # Stop after 10 epochs with no improvement\n",
    "                                                    restore_best_weights=True,  # Restore best weights\n",
    "                                                    verbose=0\n",
    "                                                )\n",
    "                    model = create_cnn(activation=activation, optimizer=optimizer(learning_rate=lr), dropout_rate=dropout_rate)\n",
    "                    history = model.fit(\n",
    "                                        train_ds,\n",
    "                                        validation_data=val_ds,\n",
    "                                        epochs=50,\n",
    "                                        batch_size=batch_size,\n",
    "                                        verbose=0,\n",
    "                                        callbacks=[early_stopping]  # Add early stopping\n",
    "                                        )\n",
    "                    # Evaluate on test set\n",
    "                    y_true = []\n",
    "                    y_pred = []\n",
    "                    for images, labels in test_ds:\n",
    "                        preds = model.predict(images,verbose=0) > 0.5\n",
    "                        y_true.extend(labels.numpy())\n",
    "                        y_pred.extend(preds.astype(\"int32\").flatten())\n",
    "\n",
    "                    f1 = f1_score(y_true, y_pred)\n",
    "                    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "                    # Store results\n",
    "                    results.append({\n",
    "                        'Learning Rate': lr,\n",
    "                        'Batch Size': batch_size,\n",
    "                        'Optimizer': optimizer.__name__,\n",
    "                        'Activation': activation,\n",
    "                        'Dropout Rate': dropout_rate,\n",
    "                        'Test Accuracy': acc,\n",
    "                        'Test F1-Score': f1\n",
    "                    })\n",
    "\n",
    "# **Find the Best Model Based on F1-Score**\n",
    "best_model = max(results, key=lambda x: x['Test F1-Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:20:24.189918Z",
     "iopub.status.busy": "2025-03-25T07:20:24.189793Z",
     "iopub.status.idle": "2025-03-25T07:20:24.192081Z",
     "shell.execute_reply": "2025-03-25T07:20:24.191822Z",
     "shell.execute_reply.started": "2025-03-25T07:20:24.189909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best CNN Configuration:\n",
      "Learning Rate: 0.0001\n",
      "Batch Size: 16\n",
      "Optimizer: RMSprop\n",
      "Activation: relu\n",
      "Test Accuracy: 0.9677\n",
      "Test F1-Score: 0.9672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print Best Model Configuration and Results\n",
    "print(\"\\n Best CNN Configuration:\")\n",
    "print(f\"Learning Rate: {best_model['Learning Rate']}\")\n",
    "print(f\"Batch Size: {best_model['Batch Size']}\")\n",
    "print(f\"Optimizer: {best_model['Optimizer']}\")\n",
    "print(f\"Activation: {best_model['Activation']}\")\n",
    "print(f\"Test Accuracy: {best_model['Test Accuracy']:.4f}\")\n",
    "print(f\"Test F1-Score: {best_model['Test F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T07:20:24.192449Z",
     "iopub.status.busy": "2025-03-25T07:20:24.192337Z",
     "iopub.status.idle": "2025-03-25T07:20:28.497026Z",
     "shell.execute_reply": "2025-03-25T07:20:28.496643Z",
     "shell.execute_reply.started": "2025-03-25T07:20:24.192441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Test Accuracy  Test F1-Score\n",
      "0                   SVM       0.933333       0.927690\n",
      "1               XGBoost       0.951220       0.944853\n",
      "2  Neural Network (MLP)       0.943089       0.937163\n",
      "3              Best CNN       0.967690       0.967213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract the best CNN results from the hyperparameter tuning process\n",
    "best_cnn_results = {\n",
    "    \"Model\": \"Best CNN\",\n",
    "    \"Test Accuracy\": best_model[\"Test Accuracy\"],  # Best CNN Accuracy\n",
    "    \"Test F1-Score\": best_model[\"Test F1-Score\"]  # Best CNN F1-Score\n",
    "}\n",
    "\n",
    "# Extract handcrafted feature-based models' best results\n",
    "handcrafted_results = [\n",
    "    {\"Model\": \"SVM\", \"Test Accuracy\": accuracy_score(y_test, svm.predict(X_test)), \"Test F1-Score\": f1_score(y_test, svm.predict(X_test))},\n",
    "    {\"Model\": \"XGBoost\", \"Test Accuracy\": accuracy_score(y_test, xgb.predict(X_test)), \"Test F1-Score\": f1_score(y_test, xgb.predict(X_test))},\n",
    "    {\"Model\": \"Neural Network (MLP)\", \"Test Accuracy\": accuracy_score(y_test, nn.predict(X_test)), \"Test F1-Score\": f1_score(y_test, nn.predict(X_test))}\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "comparison_results = pd.DataFrame(handcrafted_results + [best_cnn_results])\n",
    "print(comparison_results.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
